# 基于CLIP的本地图片搜索

这是一个基于CLIP与向量数据库的一个本地图片搜索软件，目前尚未做前后端项目整合，需要进一步优化以降低部署难度。

## 原理

输入图片阶段（**images2vec**），通过CLIP把图片批量encode到高维向量，并存入数据库。

用户输入处理阶段（**text2vec**），将用户输入的自然语言经过tokenizer处理后，encode到相同语义的高维向量空间，到数据库中与图片向量计算余弦相似度，余弦相似度大的即为符合自然语言描述的图片。

## 部署（CLI)
1. 需要准备CLIP，并准备Milvus数据库（Windows下Milvus-Lite官方不支持）
2. 编辑```CONF.py```
3. 运行```images2vec.py```
4. 运行```text2vec.py```

## TODO
 - [x] 基础功能可用
 - [x] 前端基础开发，并可用
 - [ ] 前后端整合，方便用户使用
 - [ ] 添加其他数据库支持